{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model1Var for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular shapes with different radii with large variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically circle shapes with different radii with large variability. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_diff_radii_var_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/circles_diff_radii_var_60k.npz\"\n",
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with diff radii with variabilitys already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAFoCAYAAADjMXolAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEVVJREFUeJzt3U+IZGe5B+DfKxLFeGGUiSABp5WssghyV8IFcSNk50ZcaLi6cO/GtS4U1+IfCG4EXajoShcqBrkXs5zZBERcCIlcgpBgJleNUZDvLqb7Uunpma6q91SdqlPPAw2TTnfly7z1nd95v/PVOTXGCACwnbfNPQAAOGaCFAAaBCkANAhSAGgQpADQIEgBoEGQAkDDSQdpVT1ZVber6rXzr+eq6sm5x8X2quojVfWrqvpzVb1SVT+uqvfPPS62U1WPVNVPqurFqhpV9bG5x0TPEufoSQdpkpeTfDLJe5PcTPLTJD+cdUR0vSfJd5KcJbmV5C9JvjvngGh7PskzSf4090CYxOLm6FEH6flZ6her6oWqer2qflRV71z398cYd8cYL457t3eqJP9K8sTOBsy1Jqjpz8cYPx5j/O8Y440k30ryH7sbMQ8zQT3/Ocb4+hjj+dybn8zMHL3fUQfpuU8leTrJB5M8leRzVfWBqrr7kK9Pr75AVd1N8maSbyb52t7/D7isXdMVH03y230NnCtNWU8Ogzm64u1zD2AC3xhjvJwkVfWzJB8eYzyb5Ma6LzDGuFFVjyb5bJKXdjNMNtCu6fnvPpXkS0k+Mf0Q2cAk9eSgmKMrltCRrl43eSPJu7d5kTHG35I8m+R7VfW+KQbG1to1raonkvw8yRfGGL+ZamBsZZI5ykExR1csIUjvc77E8NeHfH3mAb/6tiTvSvL4HofLGjapaVXdSvJckq+MMb4/36h5kMYc5UCd8hxdwtLufcYYf8waZ0hV9fEkryZ5IcmjSb6a5LUkv9vpANnYBjV9PMmvk3z7fKmJA7RuPZOkqt6Re5sBk+SR840t/xieAXlQTnmOLrIj3cCNJD9I8nqSP+Tejt2nxxhvzjoqOj6f5ENJvrx6Njz3oGj5fZK/595K0S/P/3xr1hHRsbg5Wk7qAGB7p96RAkCLIAWABkEKAA2CFAAaBCkANGz0OdKbN2+Os7OzHQ2F69y5c+fVMcZjU72ees5r6nomajo3c3RZ1q3nRkF6dnaW27dvbz8qWqpq0vsAq+e8pq5noqZzM0eXZd16WtoFgAZBysGqqlTV9T8IMKNF3muX4/Sg0Lz8fXfjAg6JjhQAGnSkzG7T5duLn9eZAodAR8qsOtdAXT8FDoEgBYAGS7vMYqpu0jIvMDcdKQA0CFIAaBCkANAgSNm7Xey2tYMXmIsgBYAGQcre7WKHrV27wFwEKQA0CFIAaBCkANDgzkbM4uKaZne3rWujwNx0pADQIEjPVZXPIs6g01HqRoFDcLJLuw8Kzcvfd7DevU2XedUEOCQ6UgBoOLmOdNPlW4/p2p/Lf8f+7oFjcFIdaecaqOun+zfGEKLAwTupIAWAqZ3E0u5U3aSlRgAu05ECQIMgBYAGQQoADYsP0l3strWDF4ALiw9SANilxQfpLnbYrvOaulaA03ASH3/Zp9UA9XEZYE6OQfux+I4UAHZJRzqhhz1Rxhkhp8h7fz+uu5T0oH+vNtM4iSDd9DFd173Ow/79Vf8Nb1ZOwbqPJkzMiSl17yGuFn2WdgGg4aSCtHPmte7vrj6xxNNLOBXbPp6Q7VXVJH+PU73OKTuJpd1Vmy7zbhuEApRTMMWjCc2Vze3qRjNqsZ2T6kgBYGon15FeuHzm5ewYOHS7XoJ1HNzOyQbpZd44AGzD0i4ANOw8SO0Ig2Waal47PnDsdhqkV913FliGqS6HuKzCsbO0CwANOwnSBy3nWuYF2M4+j52O05vZSZA+6I4+7vQDsJ19HjsdpzdjaRcAGnYapKtnNc5wYHk6q0xWqFiKnXekJgss36Zz3DGBJbG0CwANbhEITOKqLtMTRTgFghTYGSE6rU0fA7nt67MZS7sA0CBIAY7MLjpH3ej2LO0CHKGplnkFaJ+OFAAaBCnAEet0lLrRaVja5SD52ASs70Fz5WLZ11zaLR0pADToSJndgzZLXPV9Z9awPvNlP3SkzGrTHYeekwgcGkEKAA2WdplFp7O0gQI4JDpSAGgQpADQIEgBoEGQsndT7by1gxc4BIIUABoEKXs31W5bu3aBQyBIAaBBkAJAgyAFgAZ3NmIWF9c3t9l569oo9Lg72LR0pADQoCNlVmOMjbpSZ9Cwnavm2er3zK3tCVJmd9UErioTGyayzsmqObc9S7sA0CBIOUjOjIFjYWkXYKE23RVvN+92dKQA0KAjBVioTT+vrRPdjo4UABoEKQA0CFKAhVtnyday7vZcIwU4AatBaXfutHSkANCgIwU4MTrRaelIAaBBkAJAgyAFgAZBCgANghQAGmqT3VtV9UqSl3Y3HK5xa4zx2FQvpp6zm7SeiZoeAHN0Wdaq50ZBCgC8laVdAGgQpADQcNJBWlWPVNVPqurFqhpV9bG5x0RPVX2kqn5VVX+uqleq6sdV9f65x8V21HN5lljTkw7Sc88neSbJn+YeCJN4T5LvJDlLcivJX5J8d84B0aKey7O4mh71ZqOqejHJt5L8Z+4V5BdJPjvGeHOL1/qfJM+MMf5ryjGymSlrev56/57kv8cY/zbZIFmbei6Pmt5vCR3pp5I8neSDSZ5K8rmq+kBV3X3I16fnHTLXmLKmH03y230NnCup5/Ko6YolPP3lG2OMl5Okqn6W5MNjjGeT3Jh3WDRMUtOqeirJl5J8YvohsgH1XB41XbGEjnT12uYbSd4910CYTLumVfVEkp8n+cIY4zdTDYytqOfyqOmKJQTpfc6XGP76kK/PzD1GNrNJTavqVpLnknxljPH9+UbNg6jn8pxyTZewtHufMcYfs+YZUlW9I0md/+MjVfXOJP8Yx7wLa4HWrWlVPZ7k10m+fb7UxAFSz+U55ZousiPd0O+T/D3J40l+ef7nW7OOiI7PJ/lQki+vng3PPSi2pp7Ls7iaHvXHXwBgbjpSAGgQpADQIEgBoEGQAkCDIAWAho0+R3rz5s1xdna2o6FwnTt37rw6xnhsqtdTz3lNXc9ETedmji7LuvXcKEjPzs5y+/bt7UdFS1W9NOXrqee8pq5noqZzM0eXZd16WtoFgAZBCsyuqlJV1/8gHKBF3msXOGwPCs3L33fnNY6BjhQAGnSkwN5sunx78fM6Uw6ZjhTYi841UNdPOWSCFAAaBCkANAhSAGgQpADQYNcusFNTbRSyg5dDJUiBnboIvm6gClAOlaVdAGgQpADQIEgBoEGQAkDD5EHqVl7AVTqbhWw04pC1du2u+yikxEQANt/B67jBMbC0CwANW3ek2zwOydklkNzfabrZAsfMDRnYmoMfU/Ee4phZ2gWABh0pa1t3c5nuAjhEu7rEuHGQTvGUewfa47FNvVd/R62BOV0+hu3i+GRpFwAaNu5IO09y0J0cD4++Yi7eMxwb10iBWbn2zi6s0wxMddJmaRcAGnSk3GcX90t2Qw4u2+amLonOlPWscxly9s1Gmw7Amx+4MMXufzgUlnYBoKG1tHtVl2kJD4BDsZpHB3NDhusI0eO16yUz17iAOe3q2GNpFwAa7Nrl/3VutrHJ63O63OjjuLl0dzVBCuzNVCdrDua7t+6NMhL1sLQLAA2CFIC32PZmGadKkHKfXSzTnPrSDxyDqto6FDu/e+wEKQA0CFJg7zorFFY3dmPqHdWnxK5drmR3Jbu26XvMe4lDpSMFgAYdKQ91+T6Vm/4OXOfy+8XNFjg2gpS1OeCxD95P+7Wr5w8np1NLS7sA0KAjZWuncrYJS7aLe2yf2rFBRwoADYIUABoEKQA0CFKO2inf3xOmNNV1zVO7PpoIUgBosWuXo3NVB7r6vVM8I4YpdHbwnvK805FyVNaZ4JZ6oWfTUDzlEE0EKQC0WNoF4D5XdZlVdfLd51UEKUdh0+XaU7vXJ+yD+XQ1S7sA0KAj5Sh4CDRwqHSkANAgSAGgQZByVNZZsrWsC+yTa6QcndWgtDsXmJuOFAAadKQcNZ0oMDcdKQA0CFIAaBCkANAgSAGgQZACQIMgBYAGQQoADYIUABoEKQA0CFIAaBCkANAgSAGgQZACQIMgBYAGQQoADYIUABoEKQA0CFIAaBCkANAgSAGgQZACQIMgBYAGQQoADYIUABoEKQA0CFIAaBCkANAgSAGgQZACQEONMdb/4apXkry0u+FwjVtjjMemejH1nN2k9UzU9ACYo8uyVj03ClIA4K0s7QJAgyAFgIaTDtKqeqSqflJVL1bVqKqPzT0meqrqyaq6XVWvnX89V1VPzj0utmOOLs8Sa3rSQXru+STPJPnT3ANhEi8n+WSS9ya5meSnSX4464joMkeXZ1E1PeogPT+j+WJVvVBVr1fVj6rqnev+/hjjn2OMr48xnk/yrx0OlTVNUNO7Y4wXx71ddJV7dX1iZwPmoczR5VHT+x11kJ77VJKnk3wwyVNJPldVH6iquw/5+vS8Q+Ya7ZpW1d0kbyb5ZpKv7f3/gFXm6PKo6Yq3zz2ACXxjjPFyklTVz5J8eIzxbJIb8w6LhnZNxxg3qurRJJ+Nz+HNzRxdHjVdsYSOdHWN/Y0k755rIExmkpqOMf6W5Nkk36uq900xMLZiji6Pmq5YQpDe53yJ4a8P+frM3GNkM42avi3Ju5I8vsfhcg1zdHlOuaZLWNq9zxjjj1nzDKmq3pF7m1KS5JHzi+b/GG75dFDWrWlVfTzJq0leSPJokq8meS3J73Y6QDZiji7PKdd0kR3phn6f5O+517H88vzPt2YdER03kvwgyetJ/pB7O3afHmO8Oeuo6DBHl2dRNXWvXQBo0JECQIMgBYAGQQoADYIUABoEKQA0bPQ50ps3b46zs7MdDYXr3Llz59UxxmNTvZ56zmvqeiZqOjdzdFnWredGQXp2dpbbt29vPypaqmrSe8aq57ymrmeipnMzR5dl3Xpa2gWABkEKAA2CFICDU1XX/9CBEKQA0LDIp78AcDwe1H1e9f1DvD+8jhSA2Wy6hHuIS76CFAAaLO0CsHedzvLidw9lmVdHyl4c4nIMwBQEKQA0WNplp1Y70UNbjgGYgo6UndlkSztwOqY6BhzKsUSQAkCDIGVnHrSEa2kXTttUx4BDOZa4RspOXbzRq+pg3vQAU9KRAkCDIGUvdKPAUlnaBWDvVi/7bPu7h0JHCgANgpRZHcrnwIB5bNpdHlo3mljaZSbueARcuGruH9NOfx0pADQIUvbOrQOB6xxLN5oIUmbgjkfAkghSAGiw2YhZrHPrQJuQgGMgSJnV5ZC86jrp6veEKnBoLO0CQIMgBYAGQcrBWOfjLz4iAxwaQQoADYKUg7HORiKbjYBDI0gBoEGQAkCDz5FyUFaXbt2QATgGgpSDJUDZJydubMvSLgA06EiBk7Tu4/x0qFxHkAInY5sberjXM9extAsADTpSYPGmurWkDUlcRUcKAA2CFAAaBCmwaLt4YpCnELFKkAJAgyAFgAZBCgANPv4CLNKur2P6KAwXdKQA0KAjBRbpolPcVWeqE+WCjhQAGgQpADQIUgBoEKTAou3iWqbro6wSpADQIEgBoMHHX4DFm+qjMJZ0uYqOFAAadKTAyVjtKNftTnWhXEeQAifpckC6dy7bsrQLAA06UoDoRNmejhQAGgQpADQIUgBoEKQA0CBIAaBBkAJAgyAFgAZBCgANghQAGgQpADQIUgBoEKQA0CBIJ1BVaz/bEIBlEaQA0OAxalu6qgNd/Z5HMgGcBh0pADQIUgBoEKRbWGdjkc1HAKdBkG5hneufrpECnAZBCgANghQAGnz8ZUurS7cX10Mt5wKcHh0pADToSCegEwU4XTpSAGgQpADQIEgBoEGQAkCDIAWABkEKAA2CFAAaBCkANNQmNxOoqleSvLS74XCNW2OMx6Z6MfWc3aT1TNT0AJijy7JWPTcKUgDgrSztAkCDIAWABkEKAA2CFAAaBCkANAhSAGgQpADQIEgBoEGQAkDD/wGxnt7vfOe8sgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train and validaiton subsets\n",
    "if os.path.isfile(same_shape_diff_radii_var_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with diff radii with variabilitys already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = \\\n",
    "                                                                si.load_split_data(same_shape_diff_radii_var_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with diff radii with variability does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 422s 10ms/step - loss: 0.7506 - acc: 0.6358 - val_loss: 0.7011 - val_acc: 0.6532\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 453s 11ms/step - loss: 0.4936 - acc: 0.7753 - val_loss: 0.3008 - val_acc: 0.9049\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 448s 11ms/step - loss: 0.3466 - acc: 0.8497 - val_loss: 0.2388 - val_acc: 0.9028\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 416s 10ms/step - loss: 0.2163 - acc: 0.9130 - val_loss: 0.1528 - val_acc: 0.9415\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 402s 10ms/step - loss: 0.1332 - acc: 0.9507 - val_loss: 0.0671 - val_acc: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f270cc5d668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "same_shape_diff_radii_var_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_diff_radii.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save(same_shape_diff_radii_var_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
