{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of a CNN model for counting circular shapes with same radius in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically circle shapes with the same radius. (Code from https://keras.io/examples/mnist_cnn/ has been used as a starting point, but modified accordingly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/circles_same_radius_60k.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n",
      "Size of testing data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(same_shape_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, images_test, labels_train, labels_val, labels_test = \\\n",
    "                                                                si.load_split_data(same_shape_same_radius_fname)\n",
    "    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "    print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)\n",
    "labels_test = np_utils.to_categorical(labels_test-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n",
      "labels_test shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "42000/42000 [==============================] - 547s 13ms/step - loss: 0.5642 - acc: 0.7782 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "42000/42000 [==============================] - 540s 13ms/step - loss: 0.0117 - acc: 0.9989 - val_loss: 2.9673e-04 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "42000/42000 [==============================] - 493s 12ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 5.4727e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f683bc6e860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.4714701769019786e-05\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save(same_shape_same_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display predictions on random freshly generated images --> move to a new notebook for experiemtns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "from keras.models import load_model\n",
    "loaded_model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = loaded_model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d n̂=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
