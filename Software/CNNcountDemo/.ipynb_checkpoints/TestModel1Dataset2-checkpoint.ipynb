{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model1 on Dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting shapes in binary images: model trained on circular shapes with the same radii counting images with diamond shapes with different radii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests the CNN model for the Counting simple shapes (circles, squares or diamonds) experiment , more specifically trained on circle shapes with the same radii- Dataset1 (see the training [Notebook](https://github.com/NLeSC/XAI/blob/master/Software/CNNcountDemo/TrainModelCountCirclesSameRadius.ipynb)) and tested on Dataset2. The 'CNNcount' code resides in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diamonds_diff_radii_60k.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of testing data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and get the test subsets\n",
    "if os.path.isfile(same_shape_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    _, _, images_test, _, _, labels_test = si.load_split_data(same_shape_diff_radii_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the test images\n",
    "si.plot_12images(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_test = np_utils.to_categorical(labels_test-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "labels_test shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1d6b3d642ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d n̂=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
