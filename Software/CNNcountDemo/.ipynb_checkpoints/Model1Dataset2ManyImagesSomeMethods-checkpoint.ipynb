{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several analysers of Model1 on Dataset2 on many images using iNNvestigate\n",
    "\n",
    "## Diamond shapes with different radius\n",
    "\n",
    "This notebook shows how saliency maps are computed for 6 methods supported by the **iNNvestigate** explainability toolbox on a several test images from the Shape Images dataset. \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the dataset and split to train and test set for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3\n",
    "\n",
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "dataset = 'diamonds_diff_radii'\n",
    "same_shape_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/\" + dataset + \"_60k.npz\"\n",
    "\n",
    "\n",
    "# load the set of images with the same type and diff radius and split to train and test subsets\n",
    "if os.path.isfile(same_shape_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (diamond) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, _, images_test, labels_train, _, labels_test = si.load_split_data(same_shape_diff_radii_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of test data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (diamond) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The next part evaluates the pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "numerical_labels_test = labels_test\n",
    "labels_test = np_utils.to_categorical(numerical_labels_test-1, num_classes=None)\n",
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "\n",
    "shape_type_ind = 1 # diamonds    \n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(NMIN, NMAX+1))\n",
    "    shapes = [(shape_type_ind, np.random.randint(RMIN, RMAX)) for _ in range(n)]\n",
    "    img = si.generate_image(IMGSIZE, shapes, OCCL)\n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "        \n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "        \n",
    "    predictions = model.predict(X);\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    plt.title('n=%d nÌ‚=%d' % (n, pred))    \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of top analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    return 1-X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Signal\n",
    "    (\"pattern.net\",   {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), \n",
    "\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "       \n",
    "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    \n",
    "    (\"input_t_gradient\",     {},                        mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    \n",
    "    (\"integrated_gradients\", {\"reference_inputs\": ri},  mnistutils.heatmap,        \"Integrated Gradients\"), \n",
    "\n",
    "    (\"lrp.z\",                {},                        mnistutils.heatmap,        \"LRP-Z\"),\n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/CountingShapes/Analyzers/\" + dataset \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "    else:\n",
    "        print(\"Analyzer\", method[0], \" doesn't exist! Creating and possibly Training and [Saving]...\")\n",
    "        # Some analyzers require training.\n",
    "        analyzer.fit(images_train, batch_size=256, verbose=1)\n",
    "        if (method[0]=='pattern.net') or (method[0]=='pattern.attribution'):\n",
    "            analyzer.save_npz(fname)\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze random set of tet images with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test)\n",
    "ntim = 25\n",
    "ind = int(np.random.randint(1,nim-ntim))\n",
    "\n",
    "test_images = list(zip(images_test[ind:ind+ntim], numerical_labels_test[ind:ind+ntim]-1))\n",
    "label_to_class_name = [str(i+1) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1, 2]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: {} \".format(ind+image_nr, y_hat+1))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "    n_rows = len(grid)\n",
    "    n_cols = len(grid[0])\n",
    "    figsize = (2*n_cols, 2*(n_rows+1))\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
