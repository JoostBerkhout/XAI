{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple analysers of Model1 on single image using iNNvestigate\n",
    "\n",
    "## Circular shapes with same radius\n",
    "\n",
    "This notebook shows how saliency maps are computed for (the 9 out of all) methods supported by the **iNNvestigate** explainability toolbox on a single test image from the Shape Images dataset. (It is based on the notebook: [MNIST Neuron Selection](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/mnist_neuron_selection.ipynb)). There are errors when trying ot run the remaining 5 methods.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the dataset and split to train and test set for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of test data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3\n",
    "\n",
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "dataset = 'circles_same_radius'\n",
    "same_shape_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/\" + dataset + \"_60k.npz\"\n",
    "\n",
    "\n",
    "# load the set of images with the same type and same radius and split to train and test subsets\n",
    "if os.path.isfile(same_shape_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, _, images_test, labels_train, _, labels_test = si.load_split_data(same_shape_same_radius_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of test data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The next part evaluates the pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "labels_test shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "numerical_labels_test = labels_test\n",
    "labels_test = np_utils.to_categorical(numerical_labels_test-1, num_classes=None)\n",
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d n̂=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose a random test image to generate a heatmap for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test)\n",
    "ind=int(np.random.randint(1,nim))\n",
    "img=images_test[ind,:,:]\n",
    "img=np.reshape(img,(64,64))\n",
    "label=numerical_labels_test[ind]\n",
    "plt.imshow(img,cmap='binary')\n",
    "plt.title('ind=%d n=%d' % (ind,label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    return 1-X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                       mnistutils.bk_proj,        \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                       mnistutils.bk_proj,        \"Guided Backprop\",),\n",
    "    (\"pattern.net\",   {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), \n",
    "\n",
    "    # Function\n",
    "#    (\"gradient\",     {\"postprocess\": \"abs\"},   mnistutils.graymap,        \"Gradient\"),\n",
    "#   (\"smoothgrad\",    {\"noise_scale\": noise_scale,\"postprocess\": \"square\"},mnistutils.graymap,        \"SmoothGrad\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "     \n",
    "    \n",
    "   (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    (\"input_t_gradient\",     {},                        mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    (\"integrated_gradients\", {\"reference_inputs\": ri},  mnistutils.heatmap,        \"Integrated Gradients\"), \n",
    "#    (\"deep_lift.wrapper\",     {\"reference_inputs\": ri}, mnistutils.heatmap,        \"DeepLIFT Wrapper - Rescale\"),\n",
    "#                                                        mnistutils.heatmap,        \"DeepLIFT Wrapper - RevealCancel\"),\n",
    "    (\"lrp.z\",                {},                        mnistutils.heatmap,        \"LRP-Z\"),\n",
    "#    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), \n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/CountingShapes/Analyzers/\" + dataset \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "    else:\n",
    "        print(\"Analyzer\", method[0], \" doesn't exist! Creating and possibly Training and [Saving]...\")\n",
    "        # Some analyzers require training.\n",
    "        analyzer.fit(images_train, batch_size=256, verbose=1)\n",
    "        if (method[0]=='pattern.net') or (method[0]=='pattern.attribution'):\n",
    "            analyzer.save_npz(fname)\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the image with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_image = list(zip(images_test[ind:ind+1], numerical_labels_test[ind:ind+1]-1))\n",
    "label_to_class_name = [str(i+1) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_image):\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1, 2]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            #print(\"Analyzing with analyzer \", analyzer)\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: \".format(image_nr+ind, y_hat+1))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
