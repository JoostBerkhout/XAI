{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple analysers of Model1 on single image using iNNvestigate\n",
    "\n",
    "## Circular shapes with same radius\n",
    "\n",
    "This notebook shows how saliency maps are computed for all methods supported by the **iNNvestigate** explainability toolbox on a single test image from the Shape Images dataset. (It is based on the notebook: [MNIST Neuron Selection](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/mnist_neuron_selection.ipynb))\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import tensorflow as tf\n",
    "if(keras.backend.tensorflow_backend):\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the dataset and split to train and test set for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of test data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3\n",
    "\n",
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/circles_same_radius_60k.npz\"\n",
    "\n",
    "\n",
    "# load the set of images with the same type and same radius and split to train and test subsets\n",
    "if os.path.isfile(same_shape_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, _, images_test, labels_train, _, labels_test = si.load_split_data(same_shape_same_radius_fname)\n",
    "    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of test data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The next part evaluates the pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs\n",
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "from keras.models import load_model\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "numerical_labels_test = labels_test\n",
    "labels_test = np_utils.to_categorical(numerical_labels_test-1, num_classes=None)\n",
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d n̂=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose a random test image to generate a heatmap for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test)\n",
    "ind=int(np.random.randint(1,nim))\n",
    "img=images_test[ind,:,:]\n",
    "img=np.reshape(img,(64,64))\n",
    "label=numerical_labels_test[ind]\n",
    "plt.imshow(img,cmap='binary')\n",
    "plt.title('ind=%d n=%d' % (ind,label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a gradient analyzer. It shows how the linearized network function reacts on changes of a single feature.\n",
    "This is done by passing the model without a softmax to the analyzer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping the softmax activation from the model\n",
    "model_wo_sm = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "# Creating an analyzer\n",
    "gradient_analyzer = innvestigate.create_analyzer(\"gradient\", model_wo_sm)\n",
    "\n",
    "# Applying the analyzer\n",
    "image = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "analysis = gradient_analyzer.analyze(image)\n",
    "\n",
    "# Displaying the gradient\n",
    "plt.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the class\n",
    "\n",
    "Above the output of the neuron with the highest activation (the predicted class) is shown. Lets see the output in respect to the other classes.\n",
    "\n",
    "Lets try another analyser from the *attribution* category - The gradient_input analyzer and visualize it by means of a colored heatmap to highlight positive and negative attributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an analyzer and set neuron_selection_mode to \"index\"\n",
    "inputXgradient_analyzer = innvestigate.create_analyzer(\"input_t_gradient\", model_wo_sm,\n",
    "                                                       neuron_selection_mode=\"index\")\n",
    "\n",
    "for neuron_index in range(num_classes):\n",
    "    print(\"Analysis w.r.t. to class\", neuron_index+1)\n",
    "    # Applying the analyzer and pass that we want \n",
    "    analysis = inputXgradient_analyzer.analyze(image, neuron_index)\n",
    "    \n",
    "    # Displaying the gradient\n",
    "    plt.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
