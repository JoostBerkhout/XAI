{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model2 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diamond shapes with different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically diamond shapes with different sizes. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diamonds_diff_radii_60k.npz\"\n",
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (diamonds) with different radii already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Data formatting\n",
    "# load the set of NIM images with the same type and same radius and split to train and validation subsets\n",
    "if os.path.isfile(same_shape_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(same_shape_diff_radii_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "\n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 589s 14ms/step - loss: 0.7601 - acc: 0.6363 - val_loss: 0.4166 - val_acc: 0.8679\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 567s 13ms/step - loss: 0.4295 - acc: 0.8098 - val_loss: 0.2261 - val_acc: 0.9193\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 567s 14ms/step - loss: 0.2781 - acc: 0.8840 - val_loss: 0.1447 - val_acc: 0.9537\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 563s 13ms/step - loss: 0.1643 - acc: 0.9359 - val_loss: 0.0835 - val_acc: 0.9736\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 561s 13ms/step - loss: 0.0819 - acc: 0.9727 - val_loss: 0.0409 - val_acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fe1dacfb9e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "same_shape_diff_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diamonds_diff_radii.h5\"\n",
    "# save the trained model\n",
    "model.save(same_shape_diff_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
