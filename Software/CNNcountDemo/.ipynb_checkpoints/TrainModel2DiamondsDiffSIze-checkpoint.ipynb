{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model2 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diamond shapes with different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically diamond shapes with different sizes. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diamonds_diff_radii_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (diamonds) with different radii already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train and validation subsets\n",
    "if os.path.isfile(same_shape_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = \\\n",
    "                                                            si.load_split_data(same_shape_diff_radii_fname)\n",
    "    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (diamonds) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " 2600/42000 [>.............................] - ETA: 5:21 - loss: 1.0325 - acc: 0.4027"
     ]
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "same_shape_diff_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diamonds_radius.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(same_shape_diff_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
