{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model3 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with same size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with the same size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_same_radius_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_same_radius_fname)    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 580s 14ms/step - loss: 0.6704 - acc: 0.7115 - val_loss: 0.1404 - val_acc: 0.9858\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 471s 11ms/step - loss: 0.0910 - acc: 0.9750 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "40000/42000 [===========================>..] - ETA: 18s - loss: 0.0475 - acc: 0.9915"
     ]
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "diff_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_same_radius.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(diff_shape_same_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
