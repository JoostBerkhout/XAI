{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model3 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with same size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with the same size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_same_radius_60k.npz\"\n",
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_same_radius_fname)    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\")\n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 344s 8ms/step - loss: 0.6589 - acc: 0.7022 - val_loss: 0.1527 - val_acc: 0.9868\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 358s 9ms/step - loss: 0.0971 - acc: 0.9739 - val_loss: 0.0020 - val_acc: 0.9999\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 353s 8ms/step - loss: 0.0299 - acc: 0.9943 - val_loss: 8.5537e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 350s 8ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 5.0838e-04 - val_acc: 0.9999\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 340s 8ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 6.3980e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7ff9c1795a58>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "diff_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_same_radius.h5\"\n",
    "# save the trained model\n",
    "model.save(diff_shape_same_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
