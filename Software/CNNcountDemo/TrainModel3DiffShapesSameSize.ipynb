{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model3 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with same size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with the same size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_same_radius_60k.npz\"\n",
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAD7CAYAAADEpDe3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADbZJREFUeJzt3c2LZNd5x/HvI4QsNFp0yz1m0jIzRdDGBgstZhHIELwYgVaTzRAGa6EssjDZeOOlsRfWXyBsGLIJOEOU4FlFEGNiwkDIxnRjEKSFF8KSMEJomtG7LA+OTxbdFfdbVd+quufcc259P1CoJNTVp586/aunzz333kgpIUnK65GhByBJ68CwlaQCDFtJKsCwlaQCDFtJKsCwlaQCDFtJKqDpsI2Ir0fETkR8cPj4RUR8fehxjYX1zcfa5hMRfxER/xERDyLifkT8NCL+bOhxNR22wLvATeApYAv4N+BfBh3RuFjffKxtPpvAPwAT4ArwCfCPQw4IBg7biHgrIr4bEa9HxEcR8a8R8XjXr08pfZhSeisdnAYXwP8Cz2QbcGOsbz7WNp8eavuzlNJPU0ofp5Q+B34E/GW+EXfz6NADAP4GeAH4Avhv4G8j4t+B1+d8zd+nlP55+i8R8SHwJAcfHt/PONYWWd98rG0+K9f2iL8C/qf/IS6mhrB9JaX0LkBEvAY8l1K6DWx0fYGU0kZEXABeAt7OM8xmWd98rG0+K9f28Guf5eBD7K/7H+Jiagjb9448/xzYXuZFUkqfRcRt4H5EfC2l9H4vo2uf9c3H2uazcm0j4hngZ8B3Ukr/1dfAllXlAbKIuBwRn855vDjjSx8BngCeLjjc5ljffKxtPovUNiKuAL8AfphS+qfhRv0nNXS2p6SU3uFgHWuuiHge2OdgHecC8DLwAfBG1gE2zvrmY23zWaC2TwP/Cfz4cOmhClV2tgvYAF4FPgLe5OBo7gsppS8GHdV4WN98rG0+fwf8OfCDo53v0IMKLx4uSfm13tlKUhMMW0kqwLCVpAIMW0kqwLCVpAIW2me7tbWVJpNJpqHUb3d3dz+ldDHHa1tba5tLztqC9e1a34XCdjKZsLOzs/yoGhcR2c5dt7bWNpectQXr27W+LiNIUgGGrSQVYNhKUgGGrSQVsPRVvyLi3P/H6y5I0gE7W0kqwLCVpAIMW0kqwLCVpAIMW0kqYK3CtssOCqklzul2rE3YTielk1NjEBHH5rTzun5rEbYnJ6ITUy2bNX+d13Vb+qSGVk5YmDcxW/kZJLVv1J3teZ/0dgJqjXO6XaMO2/M6VztbtcY53a5Rhy3MnnxOSkkljT5s4XSwGrRqmQ1Em9YibOFPE9EJqTFIKR2b087r+q1N2IJBq/FxTrdjrcJWkoZi2EpSAYatJBVg2EpSAYatJBVg2ErqnacNn2bYSuqVlzM9m2ErqTdeznQ2w1ZSL7zO7nyGraSVeenH8xm2klbmpR/PZ9hK6oVXI5vPsJXUGy9nOpthK3XkumM3Xs70bEvf8FFaF0dDdvrcIJnP+pxmZyvN4XYm9cWwlaQCDFtpBveOqk+GrTSDe0fVJ8N2hOy4pPoYtiPjFZf65UZ99cWwHRGvuJSHtw1XHwzbkXCLUn6GrFZh2I6AR82l+nkG2QiklOYGqh2ZdKBL45Hr98XOdiQ8kCPVzbBtxDKfyAatVA/DtgGLbOfyiktSnQzbyi2zncuglepj2FbM7VzSeBi2Z6ghzNzOJY2LYXtERBxbHx0y0LwIijQuhu2hGv9kz7Wdy65YKs+TGip38oSFVYLW27uMU0T4PnY0ZJ3sbKl/fbSP7Vw1du5aTU3LXjqfYUsb66M1jEH18MOzPYbtGqi9c5fWgWF7aMzXFmihc1d3fni2ybA9wotEqwV+eLbJsD3DGCfrmDt3qQVNh+3Dhw+5efMmk8mEiODevXtDD6lqi3bu1jefvb09rl69yubmJpubm1y/fp29vb3OX++H52yr1jaXpsMW4Nq1a9y5c4dLly4NPZRmLPILaX3z2N7e5u7duzx48ID9/X1u3LjBrVu3FnoNl73O1kdtc4hF3qCIuA+83eP3/wbwPvBl4DHgY+A3wDKz5tnDr/2kt9GddiWldDHHC2eoLbRV33WuLcBF4KvAr3oZ3XHZagvV5wLkrS10re/0E3GIB/AW8EtgG3gKeAP4NnAZ+HDO41tnvNZvgW8O+fPU9rC+9df28L/9Afgj8L2hf64aHmOtbQ2n676SUnoXICJeA55LKd0GNoYd1mhY33xWrm1KaSMiLgAv0X/33bLR1baGNdv3jjz/HHhyqIGMlPXNp5fappQ+A24DP4mIr/QxsBEYXW1rCNtTIuJyRHw65/Hi0GNsmfXNZ4XaPgI8ATxdcLhNab22NSwjnJJSeoeOn2QR8SVgesrMYxHxOPD7dLhoo9Osbz5daxsRzwP7wOvABeBl4AMO1id1htZrW2Vnu6BfA7/j4FPr54fPrww6onGxvnlsAK8CHwFvAs8AL6SUvhh0VONQZW0X2volSVrOGDpbSaqeYStJBRi2klSAYStJBRi2klTAQvtst7a20mQyyTSU+u3u7u6nTBf0sLbWNpectQXr27W+C4XtZDJhZ2dn+VE1LiKynV9tbYep7TrcBjxnbaHeuVvqve1a3yrPIJNyO3qfrunzsYfuuqj1vXXNVmvH24CPV83vrWErSQUYtlor3gZ8vGp/bw1brZXz1u5qWNvTcmp/bw1bSSrAsNXamdXhDN35aHU1v7du/dJamv7yrcM+23VT63trZ6u1VtMvo/pV23tr2EpSAYatJBVg2EpSAYatJBVg2EpSAcXCduhT5SRpSEXCdhq0Bq7GwHmsZWQP25MT04mqltk4aFlZw7bma0tKi7Jx0CqyhW3tlzuTFmHjoFVlC9vaL3cmdWXjoD5kXUao+Qo8Ulc2DupD9gNkJyeiE1MtsnHQqops/ZpOSCemWmbjoFUUO6nBiakxsHHQsjxdV1qQQatlGLaSVIBhK0kFGLaSVIBhK0kFGLaSVIBhK0kFGLaSVIBhK0kFGLaSVIBhK0kFGLaSVIBhK0kFGLaSVIBhK0kFGLaS1lbJ+8c9Wuw7SVIljobs9Hnu6xTb2UpaK0Pdlt6wlVTEut/y3WUErZ0uv/Te+qZf05pHxKC1Pe+9zzk+O1tJWZ0MuCE73POCNOcHgWErKZuh1kdrZNhKyqLLn+xDmNW9uhtBVVrHzkSLGfJP9vOklP7/+x99npNhq4VExLGDHYau5hmqi+yq5DgMW3Xm+puWcTLQagna0gxbSdkd/ZN9XRm26qTWgx1qxzoHLXhSgzpKKc0N1JZ+kVoaq8bDzlaSCjBs1VntR5almrmMoIVMg3Xoc9yl1tjZaikGrbQYw1aSCjBsJakAw1aSCmg6bB8+fMjNmzeZTCZEBPfu3Rt6SKOyt7fH1atX2dzcZHNzk+vXr7O3tzf0sEbBuZtPrbVtOmwBrl27xp07d7h06dLQQxmd7e1t7t69y4MHD9jf3+fGjRvcunVr6GGNhnM3nxprG4scVY6I+8DbPX7/bwDvA18GHgM+Bn4DLHOo+9nDr/2kt9GddiWldDHHC2eoLfRbX4CLwFeBX/UyuuPWuba552622oK5QNf6Tq/lOMQDeAv4JbANPAW8AXwbuAx8OOfxrTNe67fAN4f8eWp79FXfw//2B+CPwPeG/rlqeDh3re2ijxpOanglpfQuQES8BjyXUroNbAw7rNFYub4ppY2IuAC8RP8dYsucu/mMrrY1rNm+d+T558CTQw1kpHqpb0rpM+A28JOI+EofAxsB524+o6ttDWF7SkRcjohP5zxeHHqMLVuhvo8ATwBPFxxuU5y7+bRe2xqWEU5JKb1Dx0+yiPgSML3232MR8Tjw+3S4YKPTutY3Ip4H9oHXgQvAy8AHHKyh6QzO3Xxar22Vne2Cfg38joNu6+eHz68MOqLx2ABeBT4C3gSeAV5IKX0x6KjGw7mbT3W1XWjrlyRpOWPobCWpeoatJBVg2EpSAYatJBWw0Navra2tNJlMMg2lfru7u/sp0znm1tba5pKztmB9u9Z3obCdTCbs7OwsP6rGRUS2U1Vn1XZd7vU1RG3XRc7agvXtWl+XESoWEcf+Kaldhm2lTgasgSu1zbCt0KxgNXCldhm2lTkvUA1cqU2GbWXOOxi2DgfLpDEybCs0K1ANWqldhm2lTgarQSu1zbCt2DRgDVqpfYZt5QxaaRwMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAJ6CVvv+CpJ860cttOgNXAlabaVwvZkwBq4knS2pcN2VrAauJJ02lJhe16gGriSdNyjy3xRSmluoHpHWEm16dIE5syupZcRZg3KoJWk01Y6QHYyWA3a8XJpSFrNylu/pgFr0I5TRBzb3mfoSsvp5aQGg3ac3HEi9cfTdSWpAMNWZ3J7n9Qvw1ZnOm9pyKUjaTFL7bOVWjb0fkutJ8NWM806ecUgUouGnreGreaaTtCIGHyySi1zzVadGLTSagxbSSrAsJWkAgxbSSrAsJWkAgxbSSrArV9aO+6s0BDsbCWpAMNWkgowbCWpAMO2cV7qUGqDB8gadTRkp8898CPVy862Qd6uRmqPYStJBRi2jfF2NVKbDNvGeLsaqU2GrSQVYNg2aFb3alcr1cutX43ydjVSW+xsG2fQSm0wbCWpgFikM4qI+8Db+YZTvSsppYs5XtjaWtuMstUWrC8d67tQ2EqSluMygiQVYNhKUgGGrSQVYNhKUgGGrSQVYNhKUgGGrSQVYNhKUgGGrSQV8H/Xvt35F5KjYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_same_radius_fname)    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\")\n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 570s 14ms/step - loss: 0.6343 - acc: 0.7116 - val_loss: 1.4612 - val_acc: 0.3787\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 550s 13ms/step - loss: 0.1157 - acc: 0.9658 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 543s 13ms/step - loss: 0.0327 - acc: 0.9933 - val_loss: 9.5542e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 510s 12ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 7.8617e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 603s 14ms/step - loss: 0.0570 - acc: 0.9905 - val_loss: 2.4746e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3146e16d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "diff_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_same_radius.h5\"\n",
    "# save the trained model\n",
    "model.save(diff_shape_same_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
