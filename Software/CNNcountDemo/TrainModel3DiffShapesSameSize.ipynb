{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model3 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with same size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with the same size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_same_radius_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_same_radius_fname)    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 570s 14ms/step - loss: 0.6343 - acc: 0.7116 - val_loss: 1.4612 - val_acc: 0.3787\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 550s 13ms/step - loss: 0.1157 - acc: 0.9658 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 543s 13ms/step - loss: 0.0327 - acc: 0.9933 - val_loss: 9.5542e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 510s 12ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 7.8617e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 603s 14ms/step - loss: 0.0570 - acc: 0.9905 - val_loss: 2.4746e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3146e16d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "diff_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_same_radius.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save(diff_shape_same_radius_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
