{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Count Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*At the moment this is work in progress and in the experimental phase. If the experiment is successsful, e.g. we get meaningful heatmaps for the task, this will turn into a real demo!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this demo is to show the ability of DNN explainability method(s) to generate meanfingful heatmaps for the relevance of the input image pixels to the output resut of a CNN model. The task is chosen to be counting shapes rather than classical classificaiton task to minimize human interpretation of the resulting heatmaps.**\n",
    "\n",
    "The explainability tool [iNNvestigate](https://github.com/albermax/innvestigate) is chosen as it offers open source implementatons of several explainability methods. Since it supports [Keras](https://keras.io/), the framework (with [Tensorflow](https://www.tensorflow.org/) as backend) is used to genrate the CNN model(s), though our vision is to go for at least [PyTorch](https://pytorch.org/) deep learning library and the related [Captum](https://captum.ai/) explainability library and definitely towards using DNN model standards such as [ONNX](https://onnx.ai/). This [list of explainability tools](https://github.com/NLeSC/XAI/blob/master/State-of-the-art/AI_Explainability_OSTools.docx) sumamrizes the availability of explainability tools.\n",
    "\n",
    "This notebook describes the Counting simple shapes (circles, squares or diamonds) experiment (see issue #50 from the [git repo](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)) and gives links to notebooks performng spesific tasks or experiments.\n",
    "\n",
    "The 'CNNCountDemo' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo). \n",
    "Code from [Keras documentation example](https://keras.io/examples/mnist_cnn/) has been used as a starting point for the  CNN model.\n",
    "\n",
    "The 4 variants of the CNN model have been trained on binary images containing simple shapes- circles, diamonds and squares (obtained via the morphological structural elements of the image processing pytnon library [skimage](https://scikit-image.org/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 different datasets of binary images for the purposes of this experiment:\n",
    "\n",
    "<b>\n",
    "Dataset1 containing images with circular shapes with the same radius.\n",
    "    \n",
    "Dataset2 containing images with diamond shapes with different radii.\n",
    "\n",
    "Dataset3 containing images with circular, diamond and square shapes with the same size/radius.\n",
    "\n",
    "Dataset4 containing images with circular, diamond and square shapes with different sizes/radii.\n",
    "</b>\n",
    "\n",
    "The notebook [GenerateShapeImages](http://localhost:8889/notebooks/GenerateShapeImages.ipynb) is used to (re)generate the datasets. Please, note that if the geenrated files are deleted and the notebook ran again, the new dataset will be different that the original as many generation parameters are random (the location of the shapes is always random).\n",
    "\n",
    "The number of shapes per image for all datasets is a random number between 1 and 3. Therefore the classification result is one of the classes '1', '2' or '3, where the class corresponds to the shapes count in the image. Each shape is at a random location and occlusion is not allowed. For the images with different shapes, the type is chosen randomly from circle, diamond and square.\n",
    "\n",
    "The images dimensions are 64x64 pixels and the datasets contain 60k images split in 42k for training, 12k for validaiton and 6k for testing. Te shape size (or 'radius') is an integer number between 2 and 6 pixels. For the shapes with the same size (radius), the average of 4 pixels is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
