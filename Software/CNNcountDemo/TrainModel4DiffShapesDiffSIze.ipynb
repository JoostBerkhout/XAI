{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model4 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with different size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with different size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_diff_radii_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_diff_radii_fname)    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 397s 9ms/step - loss: 0.7561 - acc: 0.6406 - val_loss: 0.3884 - val_acc: 0.8456\n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 414s 10ms/step - loss: 0.4413 - acc: 0.8023 - val_loss: 0.4877 - val_acc: 0.7681\n",
      "Epoch 3/8\n",
      "19000/42000 [============>.................] - ETA: 3:20 - loss: 0.3260 - acc: 0.8609"
     ]
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "diff_shape_diff_radii_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_diff_radii.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(diff_shape_diff_radii_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
