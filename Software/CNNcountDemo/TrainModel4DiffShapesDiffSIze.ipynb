{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model4 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with different size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with different size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_diff_radii_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_diff_radii_fname)    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/8\n",
      "  400/42000 [..............................] - ETA: 7:02 - loss: 1.0844 - acc: 0.3625"
     ]
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "diff_shape_diff_radii_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_diff_radii.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(diff_shape_diff_radii_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
