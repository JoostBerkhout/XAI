{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model4 for counting shapes in binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different shapes with different size/radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a CNN model for the Counting simple shapes (circles, squares or diamonds) experiment, more specifically all different shapes with different size/radius. The 'CNNcount' code is in a [git repository](https://github.com/NLeSC/XAI/tree/master/Software/CNNcountDemo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from CNNcount import shape_images as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import load\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed\n",
    "diff_shapes_diff_radii_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/diff_shapes_diff_radii_60k.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data and formatting of the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of validation data:  (12000, 64, 64, 1) and labels:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "# load the set of NIM images with the same type and same radius and split to train, test and validaiton subsets\n",
    "if os.path.isfile(diff_shapes_diff_radii_fname): # already generated- just load\n",
    "    print (\"The file containing images of the different shapes (circle, diamond, square) with different radii already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, images_val, _, labels_train, labels_val, _ = si.load_split_data(diff_shapes_diff_radii_fname)    \n",
    "    \n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of different shapes (circle, square, diamond) with different radii does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAD7CAYAAADEpDe3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADZVJREFUeJzt3U2IXNeZh/HnNUE2tgVSp9soUlDXGEEgEOGFFwMRwQsLvLI3UjD2QEZgRHbOYpaDvbCZ9eAZg5jNQCxIQryKF8bEGIGzEKYbg2FkvAjpNsEysXDLH/GHSHJmoWqp1J/1cc+599x6fnChbLpLb719+1+nT517T6SUkCTldVfbBUjSPDBsJakAw1aSCjBsJakAw1aSCjBsJakAw1aSCqg6bCPiQES8GhFrEZEi4pG2a+qTiPhhRKxExMbweDMifth2XX3guZtPRPxzRPw+Ij6NiE8i4rcR8b2266o6bIf+APwL8HHbhfTQR8AZYAFYBH4H/LrVivrFczePw8D/AANgGfgC+N82C4KWw3b4rv5vEfFeRHwWEb+JiHvG/f6U0o2U0n+mlP4A/D1jqVVqoL/XU0pr6eZlhsHNHp/IVnBFPHfzaaC3r6eUfptS+jyl9BXw38CP81U8ni6MbH8KPAb8E3AS+NeIOB4R1/c4nmq35KrM3N+IuA58A/wX8B/FX0F3ee7m02RvfwL8X6nCd/OdtgsAXkopfQQQEa8BD6WULgCH2i2rN2bub0rpUETcB/wMWM9TZpU8d/NppLcRcRJ4Dnii+RIn04WR7eh81VfA/W0V0lON9Del9FfgAvDLiHigicJ6wHM3n5l7GxEngNeBZ1NKbzdV2LS6ELbbDP9c+HKP4+m2a6zZDP29C7gXOFaw3Kp47uYzSW8jYhl4E3ghpfRKe1Xf1oVphG1SSh8y5jtZRNzNzQ9vAA4MJ9K/Td47clfj9jciTgPXgPeA+4AXgQ3g/awFVsxzN58JzttjwFvAy8Oph07o5Mh2Qh8AX3NztPXG8PFyqxX1xyHgV8BnwB+5uRLhsZTSN61W1R+eu3k8AzwIPD868m27qPBNVJLy68PIVpI6z7CVpAIMW0kqwLCVpAIMW0kqYKJ1touLi2kwGGQqpftWV1evpZSWcjy3vbW3ueTsLdjfcfs7UdgOBgNWVlamr6pyEZHtvgD21t7mkrO3YH/H7a/TCJJUgGErSQUYtpJUgGErSQUYtpJUgGErSQUYtpJUgGErSQUYtpJUQCe3xcktIvb9Gm+qLqlJjmwlqQDDVpIKMGwlqQDDVpIKMGyV3TgfSEp9Z9gqq82gNXA17wxbZbM1YA1czTPDVlnsFqwGrubVXF7U4AULee0XqBHhz0Bzx5GtGrdfkBq0mkeGrbLYLVANWs0rw1bZbA1Wg1bzzLBVVpsBa9Bq3hm2ys6glQxbSSrCsJWkAgxbSSrAsJWkAgxbSb3S1UvC5/JyXUn9Mxqym4+7tBLGka2k6tVw4yPDVpIKMGwlVW2cu8x1gWErZdCVX/B5UMtd5vyATGrIXjtTdOUXXu1xZCs1oJY/Zfuqhlt6OrKV1AubwdrVnUAc2UrqlS4GLRi20szGnSJwKmG+GbbSjMYdSXV1xKUyDFtJKsCwlaQCDFupAbUsrFd7XPolNWQ0ULu6/EjtcWQrZWDQaivDVpIKMGwlqQDDVpIKMGwlqQDDVo3zslRpO5d+qTFd33BPapMjWzWihg331F81nGeGraSqbQZt1wPXsNXM3KVAbdlrK6KuMWw1M+8LoDbUNnXlB2S6Za+T1MBU16SUdjxnu3quOrJVI2rYcE/9s/X86vL5ZtiqMSmlWyf76GMpp9FzrssMWzWu6ye9+qeGc86wlaQCqg7by5cvc/r0aRYWFlhaWuLs2bNcvXq17bJ6yf42y3M3nxs3bnDmzBkGgwERwaVLl9ouCag8bDc2Njh//jxra2usr69z8OBBzp0713ZZvWR/m+W5m9epU6e4ePEiR44cabuUW2KSuY6I+ARYb/Df/xHwF+C7wAHgc+BPwLQTMPcCPwDebaS67ZZTSks5njhDb6Gu/trbCnsLnc+Fk8Pv/aKx6rYbr7+bnxq3cQBrwDvAUWABeB/4OXAcuL7H8dQuz/cL4HKbr6lLh/21tzUeTfYW+DPwSNuvKaXUiYsaXkopfQQQEa8BD6WULgCHJnmSiDgJPAc80XyJVbO/+djbfBrpbZd0Yc7245HHXwH3T/oEEXECeB14NqX0dlOF9YT9zcfe5jNzb7umC2G7TUQcj4gv9zieHvnaZeBN4IWU0ivtVV0P+5uPvc1nkt52URemEbZJKX3IGO9kEXEMeAt4efgnhsZgf/Oxt/mM21uAiLgb2LxxwoGIuAf4Ng0nctvQyZHtBJ4BHgSeH32Ha7uoHrG/+djbvD4AvgaOAW8MHy+3WdBES78kSdOpfWQrSVUwbCWpAMNWkgowbCWpAMNWkgqYaJ3t4uJiGgwGmUrpvtXV1Wsp0w097K29zSVnb8H+jtvficJ2MBiwsrIyfVWVi4im7xx1i721t7nk7C3Y33H7W+00Qle3K5aknXTyct29jIbs5mMvzJDUddWObCWpJlWF7W5TB04pSOq6qsJ2t+kCpxEkdV1VYStJtWo8bHP/ST+yt9AdjyWpyxoN282gLTGHashKqkljYbs1YP3QSpJuayxst440HXlK0m2NTiOMzqVKkm5r/AMyg7a7nNqR2uPSrzlR8sNLSdsZtnPADy+l9hm2PeclzlI3GLY9tl+gGrhSOYZtT40bpAauVIZh21Pjrgpx9YhUhmHbY/sFqUErlWPY9py3pZS6obptcTS5lNIdc7MGbbPGmfe253JkOye8lFpql2E7RwxaqT2GrSQVYNhKUgGGrSQVYNhKUgGGrSQVYNhKUgFe1CDNyCV1GocjW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVpAIMW0kqwLCVKuHmnHXzogY1Yq8gcNH/7Db7GxH2s1KObKWO2/pGNq8j3Npft2ErddhuAVN78EwiIu4Y2df62g1bqcPcHbk/DFup47YG6zwFbZ9G9oatVIF53R25TyN7w1aqRI0Bo9tc+qVGGATKZfPcqn3ZmyNbSVWoOWjBsJWkIgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAqoO2xs3bnDmzBkGgwERwaVLl9ouqVeuXLnCww8/zOHDhzl8+DCPPvooV65cabusXrh8+TKnT59mYWGBpaUlzp49y9WrV9suqxe6mgtVhy3AqVOnuHjxIkeOHGm7lN45evQor776Kp9++inXrl3j8ccf58knn2y7rF7Y2Njg/PnzrK2tsb6+zsGDBzl37lzbZfVGF3MhJrlHZER8Aqw3+O//CPgL8F3gAPA58CdgmhtXnhx+7xeNVbfdckppKccTZ+gtNNtfgCXg+8C7jVR3p3nv7b3AD6ist2AuMG5/U0qtHcAa8A5wFFgA3gd+DhwHru9xPLXDc/0ZeKTN19O1o6n+Dv/f34B/AP/e9uvqwtHkuTt8vl8Al9t+XV04+poLXdgW56WU0kcAEfEa8FBK6QJwqN2yemPm/qaUDkXEfcDPaH6EWLNGzt2IOAk8BzzRfInV6l0udGHO9uORx18B97dVSE810t+U0l+BC8AvI+KBJgrrgZl7GxEngNeBZ1NKbzdVWA/0Lhe6ELbbRMTxiPhyj+Pptmus2Qz9vYubc4vHCpZblUl6GxHLwJvACymlV9qrug6150IXphG2SSl9yJjvZBFxNxDD/zwQEfcA36bhhI22G7e/EXEauAa8B9wHvAhscHMOTTuYoLfHgLeAl4d/HmsftedCJ0e2E/oA+Jqbo603ho+XW62oPw4BvwI+A/4InAAeSyl902pV/fAM8CDw/OjorO2ieqRzuTDR0i9J0nT6MLKVpM4zbCWpAMNWkgowbCWpgImWfi0uLqbBYJCplO5bXV29ljJdY25v7W0uOXsL9nfc/k4UtoPBgJWVlemrqlxEZLtU1d7a21xy9hbs77j9dRpBu4qI/b9I0lgMW+1oM2gNXKkZhq222RqwBq40O8NWd9gtWA1caTaGrW7ZL1ANXGl6hq1u2e8+Gd5HQ5qeYas77BaoBq00G8NW22wNVoNWmp1hqx1tBqxBOz3nuDXKsNWuDNrpuU5ZWxm2UsNcp6ydGLZSg1ynrN0YtlJDXKesvRi2UgPGDVIDd34ZtlIDxv0w0Q8d55dhKzXEK/C0F8NWapBX4Gk3hq3UMK/A004MWykDr8DTVhPtQab67PXpt0GQl/3VKEe2klSAYStJBRi2klSAc7YdNs7VRs4LSnnt9Hs4ze+dI1tJKsCwlaQCnEboOacZpG5wZCtJBTiylTKLCP/CqFhTPztHtlJG7kWmTYatlIl7kWmUYStl4F5k2so52w5znq9O4+xF5s92/jiylRrmjg3aiWErZeCODdpq5rB1DkramTs2aNTUYRsRdyxrMXSl7dyxQZumCls/aZXGZ9AKnLOVpCImDttxlrVIku40cdi6rEWSJuc0giQVMFXYuoZQkiYz9eW6m8HqpYeStL+ZpxEMWknan3O2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klSAYStJBRi2klRATLLTQkR8AqznK6fzllNKSzme2N7a24yy9RbsL2P2d6KwlSRNx2kESSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrAsJWkAgxbSSrg/wF2eR81Tg5pggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train-1, num_classes=None)\n",
    "labels_val = np_utils.to_categorical(labels_val-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "labels_train shape: (42000, 3)\n",
      "labels_val shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 7,392,131\n",
      "Trainable params: 7,392,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mcs.generate_cnncount_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elena/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 12000 samples\n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 394s 9ms/step - loss: 0.7603 - acc: 0.6350 - val_loss: 0.5261 - val_acc: 0.7373\n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 371s 9ms/step - loss: 0.4441 - acc: 0.8022 - val_loss: 0.2916 - val_acc: 0.8702\n",
      "Epoch 3/8\n",
      " 7000/42000 [====>.........................] - ETA: 4:32 - loss: 0.3174 - acc: 0.8663"
     ]
    }
   ],
   "source": [
    "# train \n",
    "mcs.train_cnncount_model(model, images_train, labels_train,images_val, labels_val, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "diff_shape_diff_radii_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_diff_shapes_diff_radii.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(diff_shape_diff_radii_model_fname)\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
